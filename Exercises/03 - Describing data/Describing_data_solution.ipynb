{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing Data\n",
    "\n",
    "### What do you find in this notebook?\n",
    "\n",
    "In this exercise, first, you will familiarize yourself with the Python libraries 'statsmodels' and 'SciPy' that let you do statistical analysis: calculate descriptive statistics, sample datapoints, study relationships between variables, and perform hypothesis testing. Then, second, you will work on a set of exercises that will let you practice your skills.\n",
    "\n",
    "Here we show a couple of examples of how to do common analyses, but there are many more useful probability distributions and statistical tests. In the linked documentation, you will find complete information, and a lot more details compared to what is outlined in this notebook:\n",
    "- [statsmodels](https://www.statsmodels.org/stable/examples/index.html), [more complete documentation](https://www.statsmodels.org/stable/stats.html)\n",
    "- [SciPy](https://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: How to use the libraries\n",
    "\n",
    "- You will be working with the full US 2015 census dataset (acs2015_county_data.csv, available at https://www.kaggle.com/muonneutrino/us-census-demographic-data#acs2015_county_data.csv). Here we load it. Take some time to familiarize yourself with the contents. One row represents one county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#load the statistical libraries\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m diagnostic\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "#load the statistical libraries\n",
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "df = pd.read_csv(data_folder + 'acs2015_county_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will focus first on income per capita across counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IncomePerCap'].hist(bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculating descriptive statisctics\n",
    "\n",
    "- Let's calculate basic descriptive statistics of the income per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IncomePerCap'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What distribution does the data come from? Here is how we can test the goodness of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does the data come from a normal distrbution?\n",
    "diagnostic.kstest_normal(df['IncomePerCap'].values, dist = 'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p_value < 0.05 -> we can reject the null hypothesis that the data comes from a normal distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how about exponential?\n",
    "diagnostic.kstest_normal(df['IncomePerCap'].values, dist = 'exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p < 0.05 -> not exponential either!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How to sample the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Often we need to find random samples from the dataset. We can do so conveniently with pandas wrappers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make 10 samples with replacement\n",
    "sample1_counties = df.sample(n = 10, replace = True)\n",
    "\n",
    "#make 10 samples without replacement\n",
    "sample1_counties = df.sample(n = 10, replace = False)\n",
    "\n",
    "#sometimes we want to sample in an ublanaced way, so that we upsample datapoints of certain characteristic,\n",
    "#and downsample the others. this can be acieved with weights parameter\n",
    "#here we sample by upsampling counties with large population\n",
    "sample2_counties = df.sample(n = 10, replace = False, weights = df['TotalPop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on avergage, the samples in the sample produce with reveighting now have higher population, as we wanted!\n",
    "print(sample1_counties['TotalPop'].mean())\n",
    "print(sample2_counties['TotalPop'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Examining relationship between two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is income per capita of a county correlated with the unemployment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df['IncomePerCap'],df['Employed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a small (0.26), but significant (p < 0.05) positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(df['IncomePerCap'],df['Employed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spearman rank coorrelation is also significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is income per capita higher in New York counties compared to California counties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['State'] == 'New York']['IncomePerCap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['State'] == 'California']['IncomePerCap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that there is a ~300$ gap. Quite a lot!\n",
    "- But is it significantly higher? Let's use a t-test. This is a two-sided test for the null hypothesis that the two independent samples have identical average (expected) values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(df.loc[df['State'] == 'New York']['IncomePerCap'], df.loc[df['State'] == 'California']['IncomePerCap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p is not smaller than 0.05 -> we cannot reject the null hypothesis that the income is the same -> there is no significant difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How to measure uncertainty\n",
    "- Now we see the importance of mesuring uncertainty and indicating it on data visualizations.\n",
    "- Visual inspection of 95% confidence intervals lets us see that the difference is not significant (the errorbars are overlapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"State\", y=\"IncomePerCap\", data=df.loc[df['State'].isin(['New York','California'])])\n",
    "plt.ylim([25000,32000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Boosting the economy by incentivizing self-employment\n",
    "\n",
    "Assume the biggest priority of the local government in 2018 is to increase per-capita income. To do so, the officials plan to adopt a strategy for incentivizing self-employment through a series of campaigns, educational programs, and dedicated funds.\n",
    "\n",
    "Since it is unethical and impossible in this setting to run a controlled experiment involving citizens (e.g., fire employees and force them to self-employ), the officials have asked you, the data scientist, to establish the effect of self-employment on the economy, relying on observational data.\n",
    "\n",
    "**A)** Using suitable methods, determine and quantify the dependency between the percentage of self-employed citizens and per capita income across all 3,212 US counties. Do citizens in counties that have a higher percentage of self-employed people earn more per capita?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# there is no clear association, very small positive correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "per_capita_self_empl = df[['State','IncomePerCap', 'SelfEmployed']]\n",
    "sn.lmplot(x='SelfEmployed',y='IncomePerCap', data=per_capita_self_empl)\n",
    "plt.xlabel(\"Percentage of Self Employed people [%]\")\n",
    "plt.ylabel(\"Income per Capita [$]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.pearsonr(per_capita_self_empl['SelfEmployed'],per_capita_self_empl['IncomePerCap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B)** The pilot program will involve all counties within a limited set of three US states. Set A includes Wisconsin, Tennessee, and  Minnesota. Quantify the dependency of per-capita income on self-employment rates across all the counties in set A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weak negative association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetA_per_capita_self_empl = per_capita_self_empl.query(\"State == 'Wisconsin' | \\\n",
    "                                                        State == 'Tennessee' | \\\n",
    "                                                        State == 'Minnesota' \") \n",
    "\n",
    "sn.lmplot(x='SelfEmployed',y='IncomePerCap', data=SetA_per_capita_self_empl)\n",
    "plt.xlabel(\"Percentage of Self Employed people [%]\")\n",
    "plt.ylabel(\"Income per Capita [$]\")\n",
    "plt.ylim([10000,50000])\n",
    "plt.xlim([0,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.pearsonr(SetA_per_capita_self_empl['SelfEmployed'],SetA_per_capita_self_empl['IncomePerCap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C)** In which state within set A is the observed effect of self-employment on per-capita income the strongest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Wisconsin, the nagative dependency is the strongest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.lmplot(x='SelfEmployed',y='IncomePerCap', data=SetA_per_capita_self_empl, hue = 'State')\n",
    "plt.xlabel(\"Percentage of Self Employed people [%]\")\n",
    "plt.ylabel(\"Income per Capita [$]\")\n",
    "plt.ylim([10000,50000])\n",
    "plt.xlim([0,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wisconsin_per_capita_self_empl = SetA_per_capita_self_empl.query(\"State == 'Wisconsin'\") \n",
    "Tennessee_per_capita_self_empl = SetA_per_capita_self_empl.query(\"State == 'Tennessee'\") \n",
    "Minnesota_per_capita_self_empl = SetA_per_capita_self_empl.query(\"State == 'Minnesota'\") \n",
    "\n",
    "print(stats.pearsonr(Wisconsin_per_capita_self_empl['SelfEmployed'],Wisconsin_per_capita_self_empl['IncomePerCap']))\n",
    "print(stats.pearsonr(Tennessee_per_capita_self_empl['SelfEmployed'],Tennessee_per_capita_self_empl['IncomePerCap']))\n",
    "print(stats.pearsonr(Minnesota_per_capita_self_empl['SelfEmployed'],Minnesota_per_capita_self_empl['IncomePerCap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D)** Set B includes New Jersey, Kansas, and Rhode Island. Repeat the analysis from steps B and C above, but now for set B. In which of the two sets A and B (if any) would you recommend incentivizing self-employment? Explain your reasoning. Hint: It is useful to add a notion of confidence to your results and explore the data visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a weak negative dependency overall, moderate to strong positive when disaggregated.\n",
    "# This is a Simpson’s Paradox: the effect is reversed when the data is aggregated.\n",
    "# We would recommend in set B, not in set A (there is significant positive correlation within\n",
    "# all states separately in set B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetB_per_capita_self_empl = per_capita_self_empl.query(\"State == 'New Jersey' | \\\n",
    "                                                        State == 'Kansas' | \\\n",
    "                                                        State == 'Rhode Island' \") \n",
    "\n",
    "sn.lmplot(x='SelfEmployed',y='IncomePerCap', data=SetB_per_capita_self_empl)\n",
    "plt.xlabel(\"Percentage of Self Employed people [%]\")\n",
    "plt.ylabel(\"Income per Capita [$]\")\n",
    "plt.ylim([10000,60000])\n",
    "plt.xlim([0,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.pearsonr(SetB_per_capita_self_empl['SelfEmployed'],SetB_per_capita_self_empl['IncomePerCap']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.lmplot(x='SelfEmployed',y='IncomePerCap', data=SetB_per_capita_self_empl, hue = 'State')\n",
    "plt.xlabel(\"Percentage of Self Employed people [%]\")\n",
    "plt.ylabel(\"Income per Capita [$]\")\n",
    "plt.ylim([10000,60000])\n",
    "plt.xlim([0,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ_per_capita_self_empl = SetB_per_capita_self_empl.query(\"State == 'New Jersey'\") \n",
    "Kansas_per_capita_self_empl = SetB_per_capita_self_empl.query(\"State == 'Kansas'\")\n",
    "RI_per_capita_self_empl = SetB_per_capita_self_empl.query(\"State == 'Rhode Island'\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.pearsonr(NJ_per_capita_self_empl['SelfEmployed'],NJ_per_capita_self_empl['IncomePerCap']))\n",
    "print(stats.pearsonr(Kansas_per_capita_self_empl['SelfEmployed'],Kansas_per_capita_self_empl['IncomePerCap']))\n",
    "print(stats.pearsonr(RI_per_capita_self_empl['SelfEmployed'],RI_per_capita_self_empl['IncomePerCap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. Data visualization and read the stats comprehension and interpretation questions.\n",
    "\n",
    "- As part of the two homeworks and the final exam, you will be at times asked to interpret your result based on the understanding of underlying concepts. The questions below can help you practice and get a sense of how well you understand the concepts covered in the class so far. Can you answer these questions confidently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1. The yearly salaries (in thousands of CHF) of 7000 people are summarized in the following box plot. If the 20th percentile of the salaries is 110,000, how many people earn between 110,000 and 114,000?\n",
    "\n",
    "- a) 2100\n",
    "- b) 700\n",
    "- c) 350\n",
    "- d) 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"boxplot.png\" style=\"width: 400px;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correct answer: c) 350. We read from boxplot that 114,00 is the 25th percentile. If 110,000 is the 20th\n",
    "# percentile, 5% of data is between, 0.05*7000 = 350 persons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. What visualizations are suitable for getting insights about the distribution of a single continuous variable?\n",
    "\n",
    "- a) Barplot and histogram\n",
    "- b) Boxplot and histogram\n",
    "- c) Scatterplot and boxplot\n",
    "- d) Barplot, boxplot, and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correct answer: b) boxplot and histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. In a new groundbreaking study, 28 out of 100 patients reported improvements after taking a new medicine. It is known that, when given a placebo, 20% of the patients report feeling better. What is the p-value assuming the null hypothesis that the probability of successful treatment in this groundbreaking study is the same as the probability of reporting feeling better under placebo, according to a one-sided binomial test? Hint: you may use the statsmodels.stats.proportion.binom_test function.\n",
    "\n",
    "- a) 0.00034\n",
    "- b) 0.0034\n",
    "- c) 0.034\n",
    "- d) 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correct answer: c) 0.034\n",
    "# from statsmodels.stats import proportion\n",
    "# print(proportion.binom_test(28, 100, 0.2, alternative='larger'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. The 95% confidence interval of the average height of 1000 people using bootstrap resampling with 10000 bootstrap samples is calculated by:\n",
    "\n",
    "- a) Sampling 1000 height values with replacement and computing the mean. This is repeated 10000 times to create a sorted list of the 10000 means. The CI is defined by the 500th and the 9500th value in sorted order.\n",
    "- b) Sampling 10000 height values without replacement and computing the mean. This is repeated 1000 times to create a sorted list of the 1000 means. The CI is defined by the 25th and the 975th value in sorted order.\n",
    "- c) Sampling 1000 height values with replacement and computing the mean. This is repeated 10000 times to create a sorted list of the 10000 means. The CI is defined by the 250th and the 9750th value in sorted order.\n",
    "- d) Sampling 1000 height values without replacement and computing the mean. This is repeated 10000 times to create a sorted list of the 10000 means. The CI is defined by the 500th and the 9500th value in sorted order.\n",
    "\n",
    "### Implement your bootstrapping function that you will use in the rest of the course. It should take an array and the number of iterations as inputs, and output 95% confidence intervals of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correct answer: c) Sampling 1000 height values with replacement and computing the mean.\n",
    "# This is repeated 10000 times to create a sorted list of the 10000 means. \n",
    "# The CI is defined by the 250th and the 9750th value in sorted order.\n",
    "\n",
    "# For implementation of bootstrapping function you can follow this post: https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_confidence_interval(data, iterations=1000):\n",
    "    \"\"\"\n",
    "    Bootstrap the 95% confidence interval for the mean of the data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: An array of data\n",
    "    - iterations: The number of bootstrap samples to generate\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple representing the lower and upper bounds of the 95% confidence interval\n",
    "    \"\"\"\n",
    "    means = np.zeros(iterations)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        means[i] = np.mean(bootstrap_sample)\n",
    "        \n",
    "    lower_bound = np.percentile(means, 2.5)\n",
    "    upper_bound = np.percentile(means, 97.5)\n",
    "    \n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "# Example usage:\n",
    "data = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "print(bootstrap_confidence_interval(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5. A study conducted at EPFL revealed a negative Spearman’s correlation between GPA and entry-level job salary. Which of the following statements is true?\n",
    "\n",
    "- a) There could be a positive Spearman’s correlation between GPA and entry-level job salary in every single department of EPFL.\n",
    "- b) Spearman correlation between GPA and entry-level job salary in every single department has to be positive.\n",
    "- c) Across all levels, as opposed to entry-level only, higher GPA scores are associated with higher job salaries.\n",
    "- d) We can infer that finishing EPFL with a higher GPA causes you to have a lower entry-level job salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correct answer: a) There could be a positive Spearman’s correlation \n",
    "# between GPA and entry-level job salary in every single department of EPFL.\n",
    "# This is known as Simpson's paradox, check out https://en.wikipedia.org/wiki/Simpson%27s_paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. The average number of requests per page during a day on a large website is 200, while the median is 15. \n",
    "\n",
    "- a) You can assume that the distribution is heavy-tailed.\n",
    "- b) You are dealing with a left-skewed distribution.\n",
    "- c) Half of the pages get more than 200 requests.\n",
    "- d) None of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The correct answer: d) None of the above. The data is not necessarily heavy-tailed nor skewed, a signle outlier\n",
    "# could shift the average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
